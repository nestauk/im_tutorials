{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "ournotebook.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "AFEFj_FQSRwt",
        "O7OtUYcJxFqz",
        "9J2n42gRSRxE",
        "jyhcxMnJj8OR",
        "cczSsVFRkK5Y",
        "EX_nQwRsSRxN",
        "jCVcknuK5HEL",
        "xbVXr_BASRxJ",
        "3NfQ7RbESRxL",
        "1RmtzFR-97iA",
        "lYXkNRo3SRxP"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoCHr2URSRwr",
        "colab_type": "text"
      },
      "source": [
        "Network Science\n",
        "===========================\n",
        "\n",
        "\n",
        "\n",
        "This tutorial gives an introduction to Network Science.\n",
        "\n",
        "\n",
        "Please use **Python3** for your default kernel this will not work otherwise!\n",
        "\n",
        "If you are using google colab this should just work :-)\n",
        "\n",
        "For those who are new to colabs/Jupyter:\n",
        "\n",
        "\n",
        "shift-enter - Executes a cell\n",
        "\n",
        "alt-enter   -  inserts a cell below\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFEFj_FQSRwt",
        "colab_type": "text"
      },
      "source": [
        "## Preamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zlmzLVRVT0M",
        "colab_type": "text"
      },
      "source": [
        "This is needed for Colab, but if you are running this in Jupyter, please install your packages separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLsxx8V5SRwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# install im_tutorial package\n",
        "!pip install git+https://github.com/nestauk/im_tutorials.git\n",
        "!pip install pybind11\n",
        "!pip install cpalgorithm\n",
        "!pip install networkx\n",
        "!pip install seaborn\n",
        "# Needed to make some of the drag and dropping work\n",
        "!pip install -U bokeh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZHVvBHWSRw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing useful Python utility libraries we'll need\n",
        "from collections import Counter, defaultdict\n",
        "import itertools\n",
        "\n",
        "# matplotlib for static plots\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pylab\n",
        "\n",
        "# makes the plots prettier\n",
        "import seaborn\n",
        "\n",
        "# numpy for mathematical functions\n",
        "import numpy as np\n",
        "\n",
        "# pandas for handling tabular data\n",
        "import pandas as pd\n",
        "\n",
        "# networkx for the analysis of graphs\n",
        "import networkx as nx\n",
        "\n",
        "#from im_tutorials.utilities import chunks\n",
        "from im_tutorials.data import *\n",
        "\n",
        "# Useful data structure to count occurances\n",
        "from collections import Counter\n",
        "\n",
        "#Iteration lib\n",
        "import itertools as it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7OtUYcJxFqz",
        "colab_type": "text"
      },
      "source": [
        "### Interactive Network Visualisation\n",
        "To visualise our networks we will use a nice library called bokeh. This will be covered in depth in a later session, so for now let us just assume that it is a magic, and all will be revealed later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo7KhHNdSRw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bokeh.io import show, output_notebook\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.palettes import Category20, Spectral4\n",
        "from bokeh.palettes import Spectral6\n",
        "from bokeh.models import Circle, MultiLine, HoverTool, TapTool, BoxSelectTool\n",
        "from bokeh.models import ColumnDataSource, LinearColorMapper, PointDrawTool\n",
        "from bokeh.models.graphs import from_networkx, NodesAndLinkedEdges\n",
        "output_notebook()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORrNOkhiSRxB",
        "colab_type": "text"
      },
      "source": [
        "Now we have everything we need to make a nice plot. Luckily, `bokeh` has built-in support for `networkx` graphs, which makes plotting and interacting with them easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt339YiOSRxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bokeh.palettes import Spectral4\n",
        "from bokeh.transform import factor_cmap\n",
        "palette = seaborn.cubehelix_palette(21)\n",
        "pal_hex_lst = palette.as_hex()\n",
        "def bokeh_plot(G,attribute=None,title='',factor=False):\n",
        "\n",
        "  # Create a plot and give it some basic features.\n",
        "  plot = figure(title=title,\n",
        "              x_range=(-2.1,2.1), y_range=(-2.1,2.1),\n",
        "             )\n",
        "  pos = nx.spring_layout(G, weight='association_strength', scale=2)\n",
        "  # Use the renderer built in to `bokeh` to transform our Graph\n",
        "  # object into something that `bokeh` can plot.\n",
        "  graph_renderer = from_networkx(G, pos, center=(0,0))\n",
        "  \n",
        "  # Draw glyphs for our nodes and assign properties for interactions.\n",
        "  if attribute!=None:\n",
        "    idx = graph_renderer.node_renderer.data_source.data['index']\n",
        "    data = [attribute[x] for x in idx]\n",
        "    graph_renderer.node_renderer.data_source.data['node_color'] = data\n",
        "\n",
        "    if factor:\n",
        "      data = [str(attribute[x]) for x in idx]\n",
        "      graph_renderer.node_renderer.data_source.data['node_color'] = data\n",
        "      uniItems = list(set(data))\n",
        "      uniItemsNum = min(20,len(uniItems))\n",
        "      mapper = factor_cmap('node_color', palette=Category20[uniItemsNum], factors=uniItems)\n",
        "      graph_renderer.node_renderer.glyph = Circle(size=10,fill_color= mapper) #, line_color=None)\n",
        "\n",
        "    else:\n",
        "      mapper = LinearColorMapper(palette=pal_hex_lst, low=min(attribute.values()), high=max(attribute.values()))\n",
        "      graph_renderer.node_renderer.glyph = Circle(size=10,fill_color={'field': 'node_color', 'transform': mapper}) #, line_color=None)\n",
        "  else:\n",
        "    graph_renderer.node_renderer.glyph = Circle(size=10,fill_color='blue') #, line_color=None)\n",
        "\n",
        "    \n",
        "  graph_renderer.node_renderer.selection_glyph = Circle(size=15, fill_color=Spectral4[2])\n",
        "  graph_renderer.node_renderer.hover_glyph = Circle(size=15, fill_color=Spectral4[1])                               \n",
        "  graph_renderer.node_renderer.muted_glyph = Circle(size=15, fill_alpha=0.9)\n",
        "  \n",
        "  # Draw glyphs for edges and assign properties for interactions.\n",
        "  graph_renderer.edge_renderer.glyph = MultiLine(line_color=\"#CCCCCC\", line_alpha=1, line_width=1)\n",
        "  graph_renderer.edge_renderer.selection_glyph = MultiLine(line_color=Spectral4[2], line_width=1.5)\n",
        "  graph_renderer.edge_renderer.hover_glyph = MultiLine(line_color=Spectral4[1], line_width=1.5)\n",
        "  \n",
        "  # Add the ability to select nodes.\n",
        "  graph_renderer.selection_policy = NodesAndLinkedEdges()\n",
        "  # Add a hover tool, that allows us to investigate nodes with a tooltip. \n",
        "  hover = HoverTool(tooltips=[(\"Name:\", \"@name\")])\n",
        "  \n",
        "  \n",
        "  # Put everything on the plot.\n",
        "  graph_renderer.node_renderer.data_source.data['name'] =graph_renderer.node_renderer.data_source.data['index']\n",
        "\n",
        "  fill_color='color'\n",
        "  plot.add_tools(hover, TapTool(), BoxSelectTool())\n",
        "  plot.renderers.append(graph_renderer)\n",
        "\n",
        "  show(plot)\n",
        "\n",
        "  # Uncomment this line if using google colab\n",
        "  output_notebook()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hw_OuSxSRw3",
        "colab_type": "text"
      },
      "source": [
        "## Lets Load Some Data\n",
        "\n",
        "\n",
        "We will start with some simple data from Les Miserable. It is a weighted undirected graph, where the weights are the number of coappearances (and the nodes are characters in the novel).\n",
        "\n",
        "If you wanted to run the same code with a different graph you would just need to place your graph here :-), although if the graph more than a few hundred nodes you might wait a while for the plotting commands so it might be worth skipping them :-)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv9-WGbfSRw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = nx.les_miserables_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ndG6N49I-mu",
        "colab_type": "text"
      },
      "source": [
        "To see the nodes and edges we use the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCXt43RIJCUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(G.nodes())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxSkXCaiJJ9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(G.edges())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnQScQKFmJre",
        "colab_type": "text"
      },
      "source": [
        "To look at the edge weights we use the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8S4wEOilwC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print([(x,y,G[x][y]['weight']) for x in G for y in G[x] if x<y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI3TR2KOmeS2",
        "colab_type": "text"
      },
      "source": [
        "We see that the edge weights vary quite a lot. For this simple example we will remove the weights to give us a undirected and unweighted graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnAWi8VNmupN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = nx.les_miserables_graph()\n",
        "for x in G:\n",
        "    for y in G[x]:\n",
        "      if x<y:\n",
        "        del G[x][y]['weight']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTnfupZ-hLHz",
        "colab_type": "text"
      },
      "source": [
        "Lets imagine we have never seen this network before.\n",
        "\n",
        "Let us follow the lectures notes:\n",
        "\n",
        "1. Look at some basic measurements\n",
        "2. Look at if the network is connected.\n",
        "3. Look at the degree distribution\n",
        "4. Visualise it :-)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLmh7PgqiqnN",
        "colab_type": "text"
      },
      "source": [
        "Some basic summary statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDBA6kwLhJym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(['Num_Nodes', G.number_of_nodes()])\n",
        "print(['Num_Edges', G.number_of_edges()])\n",
        "print(['Num Trianges', sum(nx.triangles(G).values())/3])\n",
        "print(['Clustering Coef.', nx.transitivity(G)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P0lzSrqiuFy",
        "colab_type": "text"
      },
      "source": [
        "Lets check if the network is connected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7ZVYQT-ixeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(nx.number_connected_components(G))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uhc13aijJfk",
        "colab_type": "text"
      },
      "source": [
        "Great only one component!\n",
        "\n",
        "Lets check the degree distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS4_n9V4SRxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "degrees = dict(nx.degree(G))\n",
        "pylab.hist(list(dict(degrees).values()),10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qSMwqyFjZ5o",
        "colab_type": "text"
      },
      "source": [
        "Finally draw the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpyMGOqniZJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Really simple network diagram so we can see what we are dealing with\n",
        "nx.draw(G)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq0p_BMMSRw7",
        "colab_type": "text"
      },
      "source": [
        "But we can do a little better than that, using the magic bokeh package:\n",
        "\n",
        "(try hovering over and selecting the nodes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrICPT2EZ5iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(G)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwwHAiWzSRxD",
        "colab_type": "text"
      },
      "source": [
        "Network Centrality Measures\n",
        "===========================\n",
        "\n",
        "\n",
        "As we discussed in the lecture, centrality measures are a set of statistics that attempt to capture who/what are the most important nodes in a network.\n",
        "\n",
        "However there are many different ways to do it. Here we are going to talk through a few very common ones.\n",
        "\n",
        "-   Probably hundreds of different types of centralities, though many of\n",
        "    them are very similar to each other\n",
        "\n",
        "\n",
        "We will only discuss a few well-known examples\n",
        "\n",
        "-   The simplest type of centrality is Degree Centrality\n",
        "\n",
        "-   Closeness Centrality\n",
        "\n",
        "-   Betweenness Centrality\n",
        "\n",
        "-   Eigenvector Centrality\n",
        "\n",
        "-   Katz Centrality\n",
        "\n",
        "-   Page Rank algorithm\n",
        "\n",
        "\n",
        "### Background (from slides)\n",
        "\n",
        "-   Mostly tools from Social Network Analysis\n",
        "\n",
        "-   Attempt to quantify the importance of nodes, edges, or other network\n",
        "    structures in various ways\n",
        "\n",
        "-   The choice depends on the problem and data under study, as what it\n",
        "    means to be \"most central\\\" (and most important) is obviously\n",
        "    context-dependent\n",
        "\n",
        "-   Various notions/concepts of centrality (vary by context and purpose)\n",
        "\n",
        "-   Centralities are often not robust to small perturbations either of\n",
        "    their definition or of network structure\n",
        "\n",
        "-   Be cautious about interpreting the results of centrality\n",
        "    calculations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J2n42gRSRxE",
        "colab_type": "text"
      },
      "source": [
        "### Simplest centrality: Degree Centrality\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zORfLzfbSRxE",
        "colab_type": "text"
      },
      "source": [
        "Lets first look at degree centrality.\n",
        "\n",
        "First question what is degree centrality? Do you remember?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyhcxMnJj8OR",
        "colab_type": "text"
      },
      "source": [
        "#### Answer\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB6kzgfvkRoV",
        "colab_type": "text"
      },
      "source": [
        "Just the number of connections that a node has :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cczSsVFRkK5Y",
        "colab_type": "text"
      },
      "source": [
        "#### Degree Centrality Continued\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "echLE-QfSRxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "degrees = dict(nx.degree(G))\n",
        "sorted(degrees.items(),key=lambda x:-x[1])[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23YkqmUSRxI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Gavroche_%28Les_Misérables%29.jpg/162px-Gavroche_%28Les_Misérables%29.jpg\" style=\"float: right; height: 300px;\">\n",
        "\n",
        "\n",
        "\n",
        "The most important character is *Valjean*, the main character, not that surprising. \n",
        "\n",
        "But the second most important character is *Gavroche*\n",
        "\n",
        "\n",
        "Is that right? Lets have a look at the graph so we can see what is going on :-)\n",
        "\n",
        "Note: Colour represents degree centrality - darker colours higher degree centrality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr1Wg_LQc7a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(G,degrees,'Les Miserable - Degrees')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX_nQwRsSRxN",
        "colab_type": "text"
      },
      "source": [
        "### Katz centrality (1953)\n",
        "Reminder:\n",
        "-   A variant of eigenvector centrality which allows each vertex a small\n",
        "    amount of centrality *for free* regardless of its position in the\n",
        "    network or the centrality of its neighbors\n",
        "    $$x_i = \\alpha \\sum_{j=1}^{n} A_{ij} x_j +\\beta \n",
        "    $$\n",
        "\n",
        "-   $\\alpha, \\beta > 0$\n",
        "\n",
        "-   $x = \\alpha A x + \\beta \\mbox{$1$}$\n",
        "\n",
        "\n",
        "-   (with $\\beta=1$) the Katz centrality $C_k(i)$ of vertex $i$, is\n",
        "    given by the i-th component of the eigenvector\n",
        "    $$C_k = (I - \\alpha A)^{-1} \\mbox{$1$}$$\n",
        "\n",
        "-   $I$ is the identity matrix, $\\mbox{$1$}$ denotes the\n",
        "    all-ones vector\n",
        "\n",
        "-   $\\alpha \\in (0,\\lambda)$ is a free parameter governing the balance\n",
        "    between the eigenvector term and the constant term in\n",
        "    ([\\[katzStart\\]](#katzStart){reference-type=\"ref\"\n",
        "    reference=\"katzStart\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Z4CxDBSRxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "katz = nx.centrality.katz_centrality_numpy(G)\n",
        "top10katz = sorted(katz.items(),key=lambda x:-x[1])[:10]\n",
        "top10katz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUXL5gjSRxO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Gavroche_%28Les_Misérables%29.jpg/162px-Gavroche_%28Les_Misérables%29.jpg\" style=\"float: right; height: 300px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In Katz the  most important character is *Gavroche*\n",
        "\n",
        "\n",
        "\n",
        "Is that right? Lets have a look!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGyzmmYHhWZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(G,katz,'Les Miserable - Katz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK8MH4Bi1j1_",
        "colab_type": "text"
      },
      "source": [
        "Lets try to understand what is going on here :-).\n",
        "\n",
        "We will first look at the subnetwork that just includes the top 10 nodes. We extract that as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ho9tZTt0gug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the nodes\n",
        "top10Nodes = [x[0] for x in top10katz]\n",
        "# Extract the subgraph\n",
        "Gsubgraph = G.subgraph(top10Nodes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tGIp4Xo42mT",
        "colab_type": "text"
      },
      "source": [
        "Lets now plot the graph, but rather than just giving the line can you write it yourself? \n",
        "\n",
        "No problem if not (this is all very new), the answer is hidden below :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOyUMupVk24z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCVcknuK5HEL",
        "colab_type": "text"
      },
      "source": [
        "#### Answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awRAvW54k5cH",
        "colab_type": "text"
      },
      "source": [
        "Well I would do it like this, but there are lots of other ways to do it :-).![alt text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNqvtiAn4kE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(Gsubgraph,katz,'Katz Subgraph')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3vYhzM_5giD",
        "colab_type": "text"
      },
      "source": [
        "So we can see the that the top few nodes are almost forming a clique (a fully connected subgraph). We can check this by looking at the density of the subgraph (which is almost 1):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSdLlU7f5kfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nx.density(Gsubgraph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVKWwJJz7BhK",
        "colab_type": "text"
      },
      "source": [
        "Thus, if one of them has a high Katz score, then this is added to the Katz score of each of the other nodes giving them a high Katz score. Continuing this means they all get a high Katz score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNED61aX7Aun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgc8O3Ry4j5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbVXr_BASRxJ",
        "colab_type": "text"
      },
      "source": [
        "## Page-Rank \n",
        "\n",
        "-   Issue with Katz centrality: if a vertex with high Katz centrality\n",
        "    points to many others then those others also get high centrality\n",
        "\n",
        "-   A high-centrality vertex (like *Yahoo*) pointing to one million\n",
        "    others gives *all* one million of them high centrality!\n",
        "\n",
        "-   Fix: share *Yahoo*'s contribution to the centrality of those one\n",
        "    million pages to which it is pointing\n",
        "\n",
        "-   Centrality of vertex $u$ is obtained from that of its neighbors\n",
        "    proportional to their centrality divided by their out-degree\n",
        "    $$x_i = \\alpha \\sum_{j=1}^{n} A_{ij} \\frac{x_j}{ {k_j^{out}} } + \\beta\n",
        "    $$\n",
        "\n",
        "-   Note: vertices with no out-going edges ($k_j^{out}=0$) should\n",
        "    contribute zero to the centrality of others, so set $k_j^{out}=1$\n",
        "\n",
        "\n",
        "-   $D$ diagonal matrix with $D_{ii} = \\max \\{ k_i^{out},1 \\}$\n",
        "    $$x = \\beta (I - \\alpha A D ^{-1})^{-1} 1 =  \\beta D (D - \\alpha A)^{-1} 1$$\n",
        "\n",
        "-   Set $\\beta = 1$, just a re-scaling and arrive at the Page-Rank\n",
        "    centrality $$C_{PR} = D ( D - \\alpha A)^{-1} 1$$\n",
        "\n",
        "-   $\\alpha$ governs the balance between the eigenvector term and the\n",
        "    constant term\n",
        "\n",
        "-   In practice, Google uses $\\alpha = 0.85$, no rigorous theory behind\n",
        "    this choice\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytwYl4u2SRxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pagerank = nx.pagerank(G)\n",
        "sorted(pagerank.items(),key=lambda x:-x[1])[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un_lI2-jSRxK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Mgr_Bienvenu_par_Gustave_Brion.jpg/144px-Mgr_Bienvenu_par_Gustave_Brion.jpg\" style=\"float: right; height: 300px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In pagerank the second most important character is *Marius*\n",
        "\n",
        "\n",
        "\n",
        "Is that right?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XabynpsLg7Gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(G,pagerank,'Les Miserable - PageRank')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBRIEBYD7mKi",
        "colab_type": "text"
      },
      "source": [
        "So we can see that this has fixed the problem we were seeing in Katz, but again we have to ask ourselves in this the correct choice? \n",
        "\n",
        "\n",
        "Do we think that a random walk on this network really makes sense? \n",
        "\n",
        "\n",
        "What processes on a social network graph are really like pagerank? \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NfQ7RbESRxL",
        "colab_type": "text"
      },
      "source": [
        "## Betweenness Centrality\n",
        "\n",
        "-   The betweenness centrality of an object in a network measures the\n",
        "    extent to which it lies on short paths\n",
        "\n",
        "-   A higher betweenness indicates that it lies on more short paths and\n",
        "    hence should somehow be important for traversing between different\n",
        "    parts of a network\n",
        "\n",
        "-   How many pairs of individuals would have to go through you in order\n",
        "    to reach one another in the minimum number of hops? Who has higher\n",
        "    betweenness, X or Y?\n",
        "\n",
        "### Betweenness Centrality of a Vertex\n",
        "\n",
        "-   The geodesic betweenness $B_{n}(i)$ of a **vertex** in a weighted,\n",
        "    undirected network is\n",
        "    $$B_{n}(i) =  \\sum_{s,t \\in G} \\frac{ \\Psi_{s,t}(i) }{\\Psi_{s,t}}$$\n",
        "    where vertices $s,t,i$ are all different from each other\n",
        "\n",
        "-   $\\Psi_{s,t}$ denotes the number of shortest paths (geodesics)\n",
        "    between vertices $s$ and $t$\n",
        "\n",
        "-   $\\Psi_{s,t}(i)$ denotes the number of shortest paths (geodesics)\n",
        "    between vertices $s$ and $t$ **that pass through vertex** $i$.\n",
        "\n",
        "-   The geodesic betweenness $B_n$ of a network is the mean of $B_n(i)$\n",
        "    over all vertices $i$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99Eg2mgSRxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "betweenness = nx.betweenness_centrality(G)\n",
        "sorted(betweenness.items(),key=lambda x:-x[1])[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L2eKCnySRxM",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Mgr_Bienvenu_par_Gustave_Brion.jpg/144px-Mgr_Bienvenu_par_Gustave_Brion.jpg\" style=\"float: right; height: 300px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "In Betweenness the second most important character is *Myriel*\n",
        "\n",
        "\n",
        "\n",
        "Is that right?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h8ivzaThJAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(G,betweenness,'Les Miserable - Betweenness')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0apgXmpI8zYL",
        "colab_type": "text"
      },
      "source": [
        "Betweeness rewards bottlenecks of information as many paths go through them.\n",
        "\n",
        "Have a look at the plot, can you think why Myriel ends up being the (second) most important?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RmtzFR-97iA",
        "colab_type": "text"
      },
      "source": [
        "### Answer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ42IaGJ-nva",
        "colab_type": "text"
      },
      "source": [
        "Myriel is the only path between the rest of the network and 7 other characters. To all of the paths between those characters and all other characters go through him. Thus, even through he is not very *central* in the plot, he is very important for information flow in the network. \n",
        "\n",
        "It is for this reason that one use of  betweenness is to select the best nodes to remove in a network to split it up :-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYXkNRo3SRxP",
        "colab_type": "text"
      },
      "source": [
        "# So who is the most important???? \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Gavroche_%28Les_Misérables%29.jpg/162px-Gavroche_%28Les_Misérables%29.jpg\" style=\"float: right; height: 300px;\">\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Mgr_Bienvenu_par_Gustave_Brion.jpg/144px-Mgr_Bienvenu_par_Gustave_Brion.jpg\" style=\"float: right; height: 300px;\">\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Well it depends on what is important to your problem. \n",
        "\n",
        "Is number of connections important to you? \n",
        "- Well then maybe it is **Gavroche** from the Degree Centrality.\n",
        "\n",
        "Katz Centrality: Are the number of walks of different lengths between nodes important in your network?\n",
        "- Maybe it is again **Gavroche**\n",
        "\n",
        "Is the flow of random walkers on your network important to you?\n",
        "- Maybe it is **Myriel** from the pagerank calculation\n",
        "\n",
        "Are shortest paths important to you in your network? \n",
        " - Well then maybe it is **Myriel** from the Betweenness calculation.\n",
        "\n",
        "etc\n",
        "\n",
        "\n",
        "**Important Questions to consider:**\n",
        "- What does an edge mean in your network?\n",
        "- What does a path mean in your network?\n",
        "\n",
        "\n",
        "**If we/you have some time**\n",
        "\n",
        "If we/you have some extra time here why not try out another centrality measure.\n",
        "\n",
        "I would advise trying out closeness centrality (nx.closeness_centrality), but other choices are also good :-)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8YqmT3ASRxQ",
        "colab_type": "text"
      },
      "source": [
        "# Mesoscale Structure - Community Detection/Core-periphery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7t2ADd6SRxQ",
        "colab_type": "text"
      },
      "source": [
        "## Community Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6LyVpqWSRxR",
        "colab_type": "text"
      },
      "source": [
        "Community detection is the process of finding sets of nodes in a network that are densely internally. Algorithms for this process generally find the boundaries of communities by analysing the density of connections between a group of nodes with respect to the density of connections outside of this group. A pair of nodes is more likely to be connected if they are both members of the same community.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/nestauk/im_tutorials/blob/master/img/community_detection.png?raw=true\" alt=\"communities\" width=200>\n",
        "\n",
        "There are [many different types of community detection](https://github.com/benedekrozemberczki/awesome-community-detection). Here we will use the Louvain Method, as there is an actively maintained, easy to use Python implementation, [`python-louvain`](https://python-louvain.readthedocs.io).\n",
        "\n",
        "It optimises a quantity called modularity:\n",
        "\n",
        "$$  \\sum_{ij} (A_{ij} - \\lambda P_{ij}) \\delta(c_i,c_j) $$\n",
        "\n",
        "$A$ - The adjacency matrix\n",
        "\n",
        "$P_{ij}$ - The expected connection between $i$ and $j$.\n",
        "\n",
        "$\\lambda$ - Resolution parameter\n",
        "\n",
        "Can use lots of different forms for $P_{ij}$ but the standard one is the so called configuration model:\n",
        "\n",
        "$P_{ij} = \\frac{k_i k_j}{2m}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7opcC0EXSRxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `python-louvain` imports as `community`\n",
        "import community"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDexUuAaSRxS",
        "colab_type": "text"
      },
      "source": [
        "To find which community each research topic is in, we apply `best_partition` to our cooccurrence network. We can vary the resolution to change granular the community detection is. We also pass in the name of the edge weight that we want the method to use when determining where community boundaries are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJWWc2-ZSRxU",
        "colab_type": "text"
      },
      "source": [
        " **Import Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa31KEwYSRxU",
        "colab_type": "text"
      },
      "source": [
        "The data for this project is stored as a csv on Amazon Web Services (AWS) S3, a static cloud file storage service. The `im_tutorials` module contains functions for pulling these datasets directly into a dataframe in our notebooks. (Behind the scences wer are using `smart_open` and `pandas` to pull the data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDziMT5QSRxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from im_tutorials.data import arxiv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRVHm-gD_3mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkD8hgeT_3ZF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abwFnJVYqeYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arxivData = arxiv.arxiv_sample_2017()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4mWK0H9Ae6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arxivData.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp7DFmsGAkpC",
        "colab_type": "text"
      },
      "source": [
        "Okay so we will now make a network out of this data. \n",
        "\n",
        "The simplest network we can make is a co-authorship network, where nodes are authors and there is an edges between a pair of nodes if they have authored a paper together.\n",
        "\n",
        "First we need to get a unique identifier for an author. For simplicity we will just use name, fine for this demo **but this can be problematic -  many people have the same name**.  \n",
        "\n",
        "To do this we will use this function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jGA67fOIUo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def formatName(x):\n",
        "  if 'forenames' in x:\n",
        "    return x['forenames'] +' '+x['keyname']\n",
        "  else:\n",
        "    return 'Unknown' +' '+x['keyname']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7epd0HJIbr_",
        "colab_type": "text"
      },
      "source": [
        "To make the network small enough for this session we will only consider:\n",
        "- The first 40000 papers\n",
        "- Only papers that have 3 or fewer authors - to avoid cliques!\n",
        "\n",
        "We will first count the number of co-publications a pair of authors have and then make the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyLtk_3Tq_E4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Count the \n",
        "edgeCounter = Counter()\n",
        "for authorList in arxivData['authors'][:40000]:\n",
        "    if len(authorList)>3:\n",
        "      continue\n",
        "   # Format the authors names\n",
        "    authorListFormatted = [formatName(x) for x in authorList]\n",
        "    # Get all pairs of authors\n",
        "    for author1,author2 in it.combinations(authorListFormatted,2):\n",
        "      # Use string ordering to give order\n",
        "      if author1<author2:\n",
        "        edgeCounter[(author1,author2)]+=1\n",
        "      else:\n",
        "        edgeCounter[(author2,author1)]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SnRPngpJJ9I",
        "colab_type": "text"
      },
      "source": [
        "Generate the graph from the co-publication counts. (Note there are faster ways to do this if the graph is large - see networkx docs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GFcCPzdJHrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Garxiv=nx.Graph()\n",
        "for item in edgeCounter:\n",
        "  Garxiv.add_edge(item[0],item[1],weight=edgeCounter[item])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgvTBauOJzj-",
        "colab_type": "text"
      },
      "source": [
        "As before lets explore our new graph a little:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRlF3HbxJ4gQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(['Num_Nodes', Garxiv.number_of_nodes()])\n",
        "print(['Num_Edges', Garxiv.number_of_edges()])\n",
        "print(['Num Trianges', sum(nx.triangles(Garxiv).values())/3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xT3mhJVKlLO",
        "colab_type": "text"
      },
      "source": [
        "Lets now check for the number of components.\n",
        "\n",
        "We could analyse the whole graph (sometimes this is useful) but for this colab on a small google machine it is probably better to use a smaller graph.\n",
        "\n",
        "Notice that the number of nodes and the number of edges is about equal.\n",
        "\n",
        "**This means that there is lots of disconnected components that dont really contribute to the network structure**\n",
        "\n",
        "Thus as before we will focus on the largest connected component (LCC). \n",
        "\n",
        "This is the largest set of vertices for which there is a path between any pair of them. \n",
        "\n",
        "First we will get all of the connected components:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14DQIoCzJi7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "components = list(nx.connected_components(Garxiv))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLFFaiDbLm8B",
        "colab_type": "text"
      },
      "source": [
        "Let us look at the histogram of sizes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtJIojeZLqNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pylab.hist([len(x) for x in components])\n",
        "pylab.yscale('log')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k87vd9oSMm44",
        "colab_type": "text"
      },
      "source": [
        "Let us first get the nodes for the largest component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl-W-WXLuezv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GarxivLCCNodes = max(components,key=lambda x:len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYVfuPayMybX",
        "colab_type": "text"
      },
      "source": [
        "Then generate the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KUliCnTMqfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GarxivLCC = Garxiv.subgraph(GarxivLCCNodes).copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1qH3wFRMABr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(['Num_Nodes', GarxivLCC.number_of_nodes()])\n",
        "print(['Num_Edges', GarxivLCC.number_of_edges()])\n",
        "print(['Num Trianges', sum(nx.triangles(GarxivLCC).values())/3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4KycTvaM8AS",
        "colab_type": "text"
      },
      "source": [
        "Much smaller and easier to deal with :-). \n",
        "\n",
        "Lets have a look at the graph:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NluHOiDJNDDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(GarxivLCC,title='Arxiv Network')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7eMpGMBNTeZ",
        "colab_type": "text"
      },
      "source": [
        "Lets now look at the communities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd68gVXMuEX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "partition = community.best_partition(GarxivLCC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzKzhOsMNX6K",
        "colab_type": "text"
      },
      "source": [
        "How many did we end up with? (The number of communities in modularity optimisation is up to the algorithm - with some caveats!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mnzniHHv3u8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max(partition.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LsPf0ijZK-l",
        "colab_type": "text"
      },
      "source": [
        "We can visualise the communities, to see them we will plot each community in a different colour.\n",
        "\n",
        "To do this we use factor=True as this is a categoricial variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG8SKC1Yv8Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bokeh_plot(GarxivLCC,partition,'Co-Authorship',factor=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJAEhVjfYKq9",
        "colab_type": "text"
      },
      "source": [
        "The network seems to split into several nice groups :-).\n",
        "\n",
        "Some of this is just because the network is so sparse, but we should check what the groups mean :-)\n",
        "\n",
        "Let us first extract what each of the authors specialise in using the tags on the papers.\n",
        "\n",
        "For simplicity, rather than the complete tags we will just use the overall subject areas\n",
        "\n",
        "If you are feeling particularly keen you could also try using the text in the titles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpAuraDI4376",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data structure to hold the number of papers of each type.\n",
        "author2properties = {x:Counter() for x in GarxivLCC}\n",
        "\n",
        "def get_SubjectArea(x):\n",
        "   # We are interested in the subject area \n",
        "   # (everything before the fullstop)\n",
        "   # If you have soe time change this function \n",
        "   # and see what difference it makes\n",
        "   return x.split('.')[0]\n",
        "\n",
        "# This is not the best way to do this\n",
        "# but for simplicity it is acceptable on such a small dataset\n",
        "for idx,row in arxivData.head(40000).iterrows():\n",
        "    authors = row.authors\n",
        "    if len(authors)>3:\n",
        "      continue\n",
        "    authorsFmt = [formatName(x) for x in authors]\n",
        "    for x in authorsFmt:\n",
        "      # Filtering only authors in our network\n",
        "      if x in GarxivLCC:\n",
        "        for y in row.category_ids:\n",
        "            author2properties[x][get_SubjectArea(y)]+=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSontpNXrTkk",
        "colab_type": "text"
      },
      "source": [
        "Lets now compute the percentage of authors that have written a paper in anyone of our areas.\n",
        "\n",
        "First we will get the number of nodes in each of the communities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq9FdNNV44OZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "communitySizes = Counter(partition.values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpwfZKprrgz3",
        "colab_type": "text"
      },
      "source": [
        "Then we will compute the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNAEmdk044JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "community2properties = {x:Counter() for x in range(1+max(partition.values()))}\n",
        "# For each node\n",
        "for x in partition:\n",
        "     # Get their group\n",
        "    group = partition[x]\n",
        "    # For each subject area they have written a paper in\n",
        "    for y in author2properties[x]:\n",
        "        community2properties[group][y.split('.')[0]]+=1\n",
        "# Normalise by the size of the communities\n",
        "for x in community2properties:\n",
        "     for y in community2properties[x]:\n",
        "        community2properties[x][y]/=communitySizes[x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39IlHu0r4BF",
        "colab_type": "text"
      },
      "source": [
        "Lets check out a given community:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dhiZedg44W5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "community2properties[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70LwvO40sA17",
        "colab_type": "text"
      },
      "source": [
        "The output of the Louvain algorithm is stochastic, so you might get different results :-)\n",
        "\n",
        "The first time I ran this I obtained:\n",
        "\n",
        "\n",
        "```\n",
        "print(community2properties[1])\n",
        "Counter({'astro-ph': 0.6, 'hep-ex': 0.2, 'hep-ph': 1.0, 'hep-th': 0.4})\n",
        "```\n",
        "\n",
        "A community that is clearly related to astro and high energy physics :-). \n",
        "\n",
        "There are different ways to validate communities, we don't have time to go through this here, but would be happy to talk about it after. Some options include:\n",
        "\n",
        "* Hypergeometric test of the labels (there is an over-representation of a labels in a given group) - watch out for multiple comparisons here!.\n",
        "* Comparsion to a known division using a partition similarity measure (Adjusted Rand Index, Normalised Mutual Information, etc).\n",
        "\n",
        "Again not enough time, but we can also use community labels for prediction, as we would expect nodes in the same community to behaviour similarly. \n",
        "\n",
        "**If we happen to have more time here**\n",
        "\n",
        "Can you visualise the commnuity categories?\n",
        "\n",
        "Or you could checkout the other notebook on dynamic community detection (written by George)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "afjsgUvpqo7p"
      },
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kdE9xB8SRx2",
        "colab_type": "text"
      },
      "source": [
        "🎈We made it!\n",
        "\n",
        "In this tutorial, we have constructed and analysed two networks. \n",
        "\n",
        "First we analysed the network from Les Miserable and learned about centrality measures. Crucially that it is important to choose your centrality measure carefully.\n",
        "\n",
        "Second, we briefly look at community detection in a co-authorship network. We constructed the network by considering a filtered list of papers from the arxiv dataset. We extracted author information from each paper, and then used this to form a weighted network.\n",
        "\n",
        "Using this network we learned about connected components, and then performed community detection in the resulting network, finding that the clusters appear to relate to subject field.\n",
        "\n",
        "\n",
        "🗺**Where can we go from here?**\n",
        "\n",
        "As we discussed in the slides, all of these techniques can be used in any network you like. What would make the most sense in your domain/dataset?\n",
        "\n",
        "How would it be best to construct a network from that data? For this network which centrality measure makes the most sense? What would the communities look like in this dataset, and would they relate to properties of the network?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcMHZp5kwRMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}