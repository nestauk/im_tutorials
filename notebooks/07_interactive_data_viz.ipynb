{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Innovation Mapping with Python\n",
    "\n",
    "Bring some life to your innovation mapping notebook analysis with interactive data viz! ðŸ•¹\n",
    "\n",
    "---\n",
    "\n",
    "This tutorial covers a few examples of interactive data visualisation with Python that can be used to create rich notebooks or prototypes for web visualisations.\n",
    "\n",
    "In this tutorial, we are going to be based on Bokeh and will make use of HoloViews, GeoViews and Datashader. There are many options for interactive data visualisation with Python however, including Altair, Plotly, Dash, and even Matplotlib, so try them out too!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# install im_tutorial package\n",
    "# !pip install git+https://github.com/nestauk/im_tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful Python tools\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "# matplotlib for static plots\n",
    "import matplotlib.pyplot as plt\n",
    "# networkx for networks\n",
    "import networkx as nx\n",
    "# numpy for mathematical functions\n",
    "import numpy as np\n",
    "# pandas for handling tabular data\n",
    "import pandas as pd\n",
    "# seaborn for pretty statistical plots\n",
    "import seaborn as sns\n",
    "\n",
    "from im_tutorials.data.gtr import gtr_table, gtr_link_table, gtr_table_list\n",
    "\n",
    "pd.set_option('max_columns', 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The im_tutorials datasets module can be used to easily load datasets.\n",
    "\n",
    "from im_tutorials.data.sdg import sdg_web_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GtR Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_projects_df = gtr_table('projects')\n",
    "gtr_funds_df = gtr_table('funds')\n",
    "gtr_funds_link_table = gtr_link_table('funds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Join funding table to link table to get project ids. Groupby project to get start and end date, sum of funding.\n",
    "- Group leads and collaborators and create network\n",
    "- Join with project descriptions and make collaboration network with SDGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_funds_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_funds_link_table.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_funds_df = gtr_funds_df.merge(gtr_funds_link_table, left_on='id', right_on='id')\n",
    "gtr_funds_df = gtr_funds_df.drop_duplicates(['project_id', 'amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_funds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Earliest start date:', gtr_funds_df['start'].min())\n",
    "print('Earliest end date:', gtr_funds_df['end'].min())\n",
    "print('\\n')\n",
    "print('Latest start date:', gtr_funds_df['start'].max())\n",
    "print('Latest end date:', gtr_funds_df['end'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_funds_df['start'].dt.year.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_funds_df['end'].dt.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_start_year = 2006\n",
    "max_start_year = 2019\n",
    "max_end_year = 2030\n",
    "\n",
    "gtr_funds_df = gtr_funds_df[(gtr_funds_df['start'].dt.year >= min_start_year) & \n",
    "                            (gtr_funds_df['start'].dt.year < max_end_year)]\n",
    "gtr_funds_df = gtr_funds_df[(gtr_funds_df['end'].dt.year <= max_end_year)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_projects_funds_df = gtr_projects_df.merge(\n",
    "    gtr_funds_df, left_on='id', right_on='project_id', \n",
    "    how='left', suffixes=('_proj', '_fund'))\n",
    "\n",
    "gtr_project_funds_df = gtr_projects_funds_df.drop_duplicates(subset=['project_id'])\n",
    "gtr_project_funds_df['start_year'] = gtr_project_funds_df['start_fund'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column that just has the start year\n",
    "gtr_project_funds_df['start_year'] = gtr_project_funds_df['start_fund'].dt.year\n",
    "# group funds by start of year and funder\n",
    "amount_year_sum = gtr_project_funds_df.groupby(['start_year', 'leadFunder'])['amount'].sum()\n",
    "amount_year_sum = amount_year_sum.loc[2006:2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_year_sum.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_year_sum = amount_year_sum.unstack()\n",
    "amount_year_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 3\n",
    "amount_year_sum_rolling = amount_year_sum.rolling(rolling_window).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Usual Suspect\n",
    "\n",
    "**Matplotlib** is a very popular library for plotting in Python. It can be used to produce publication worthy plots, but is typically restricted to producing static images.\n",
    "\n",
    "Here we will plot the total amounts awarded by each funder in each year, with a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(amount_year_sum_rolling, marker='o')\n",
    "ax.legend(amount_year_sum_rolling.columns)\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Total Funding (Â£)')\n",
    "ax.set_title('Total Funding Over Time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Level\n",
    "\n",
    "Matplotlib is great for scientific plots, but for interaction we need to look elsewhere. Here we are going to try **Bokeh** to produce an interactive version of exactly the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need these to make plot visible in notebook\n",
    "from bokeh.io import show, output_notebook\n",
    "# figure object to \n",
    "from bokeh.plotting import figure\n",
    "# basic bokeh building blocks\n",
    "from bokeh.models import ColumnDataSource, Circle, Line\n",
    "from bokeh.models import PrintfTickFormatter, HoverTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure object with desired dimensions\n",
    "p = figure(width=550, height=350,\n",
    "           title='Total Awards by Funder over Time')\n",
    "\n",
    "# loop through columns, select color, plot line and circles\n",
    "for i, c in enumerate(amount_year_sum.columns):\n",
    "    color = Category10_9[i]\n",
    "    p.line(\n",
    "        x=amount_year_sum_rolling.index.values, \n",
    "        y=amount_year_sum_rolling[c], \n",
    "        legend=c,\n",
    "        color=color,\n",
    "        line_width=2,\n",
    "        alpha=0.7,\n",
    "        name=c,\n",
    "        muted_alpha=0.1,\n",
    "        muted_color=color\n",
    "          )\n",
    "    p.circle(\n",
    "        x=amount_year_sum_rolling.index.values, \n",
    "        y=amount_year_sum_rolling[c], \n",
    "        legend=c,\n",
    "        color=color, \n",
    "        name=c,\n",
    "        muted_alpha=0.1, \n",
    "        muted_color=color\n",
    "    )\n",
    "\n",
    "# build a hover tool that will display funding amount (y value), \n",
    "# year (x value) and funding amount\n",
    "hover = HoverTool(tooltips=[('Amount', 'Â£@y{( 0.00 a)}'),\n",
    "                            ('Year', '@x{%F}'),\n",
    "                            ('Funder', '$name')],\n",
    "                 )\n",
    "p.add_tools(hover)\n",
    "\n",
    "# add labels and formatting\n",
    "p.xaxis.axis_label = 'Year'\n",
    "p.yaxis.axis_label = 'Total Funding'    \n",
    "p.yaxis[0].formatter = PrintfTickFormatter(format=\"Â£%.1e\")\n",
    "# add interactive legend\n",
    "p.legend.click_policy = \"mute\"\n",
    "p.legend.location = 'top_left'\n",
    "p.legend.label_text_font_size = '6pt'\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bokeh Scatter (Circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = (gtr_funds_df['end'] - gtr_funds_df['start']).dt.days / 365.25\n",
    "amount = gtr_funds_df['amount']\n",
    "\n",
    "p = figure(width=550, height=350, y_axis_type=\"log\")\n",
    "p.grid.visible = False\n",
    "\n",
    "p.circle(x=duration, y=amount, size=1, alpha=0.05)\n",
    "\n",
    "p.xaxis.axis_label = 'Duration (years)'\n",
    "p.yaxis.axis_label = 'Funding Amount (Â£)'\n",
    "\n",
    "p.add_tools(HoverTool(\n",
    "    tooltips=[(\"Duration\", \"$x\"), (\"Amount\", \"$y\")],\n",
    "    mode=\"mouse\", point_policy=\"follow_mouse\"\n",
    "))\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declarative Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is it?\n",
    "\n",
    "> By declarative, we mean that while plotting any chart, you only need to declare links between data columns to the encoding channels, such as x-axis, y-axis, colour, etc. and rest all of the plot details are handled automatically. Letâ€™s understand it by an example. \n",
    "\n",
    "[https://www.analyticsvidhya.com/blog/2017/12/introduction-to-altair-a-declarative-visualization-in-python/](https://www.analyticsvidhya.com/blog/2017/12/introduction-to-altair-a-declarative-visualization-in-python/)\n",
    "\n",
    "Instead of having to faff around with lots of details, declarative plotting libraries do lots of the work behing the scenes and are loaded with good default settings. These can normally be overridden by just changing some options, making the code a lot cleaner, and the workflow a lot faster for exploratory analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarative Hexbin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our declarative data visualisation, we are going to use **Holoviews**. Holoviews is a library that simply puts your data, the relationships between the data and the plot, and any plot settings you want to apply in to a structure that is ready to be plotted. \n",
    "\n",
    "It can't actually do the plotting on its own, so we need to specify a \"back end\" to do the work. Because of this, Holoviews can actually be initialised with different plotting libraries as the back end. In this case we will use Bokeh as we want to retain the interactivity, but we could also have used Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hex = pd.DataFrame({'Project Duration (years)': duration,\n",
    "                   'Funding Amount': np.log10(amount[mask])})\n",
    "\n",
    "hx = hv.HexTiles(df_hex)\n",
    "hx.opts(width=550, height=350, logz=True, yformatter='Â£10^%d',\n",
    "        tools=['hover'], hover_color='pink', hover_alpha=0.7,\n",
    "        title='Funding Amount by Project Duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the plotting options for a specific Holoviews chart type, you can interrogate the object with `?` notation.\n",
    "\n",
    "```python\n",
    "from holoviews import opts\n",
    "opts.HexTiles?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're at it, let's see what it would have looked like to make the scatter plot above with Holoviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat = hv.Scatter(df_hex.sample(frac=0.1))\n",
    "scat.opts(width=550, height=350, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holoviews is also great at handling layouts. Let's overlay a scatter on top of the hexbin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.opts.HexTiles??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat = hv.Scatter(df_hex.sample(frac=0.05))\n",
    "scat.opts(alpha=0.3, color='white', size=0.5)\n",
    "\n",
    "hx * scat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular type of interactive chart is a map, due to the ability to zoom and pan. This makes sense as large geographic datasets can have both high level and low level structure.\n",
    "\n",
    "Let's pull the details of the organisations in Gateway to Research and explore their locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_org_locs_df = gtr_table('organisations_locations')\n",
    "gtr_org_locs_df.head()\n",
    "\n",
    "# drop orgs where no location is available\n",
    "gtr_org_locs_df = gtr_org_locs_df[(~pd.isnull(df_org_locs['latitude'])) &\n",
    "                                  (~pd.isnull(df_org_locs)['longitude'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folium** is a Python wrapper around the web visualisation mapping library Leaflet.js. It can be easily used to produce familiar looking visualisations, using openly available map tile sets. Let's use it to make a cluster marker style plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from im_tutorials.data.gis import country_basic_info\n",
    "country_df = country_basic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster, FastMarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_c, lng_c = country_df.set_index('alpha3Code').loc['GBR']['latlng']\n",
    "\n",
    "cluster_map = folium.Map(location=[lat_c, lng_c], zoom_start=5, width=550, height=550)\n",
    "cluster_map.add_child(FastMarkerCluster(data=gtr_org_locs_df[['latitude', 'longitude']].values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folium can also be used to plot vectors, rasters and choropleths.\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. Change the marker icon.\n",
    "2. Remove the organisations at duplicate addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datashader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does one job. Does it well.\n",
    "\n",
    "Sometimes, you may have a lot of points to plot. We saw earlier with Bokeh that it took a while to plot a few thousand scatter points. We also saw that the hexbin did a much better job of showing the information at a low zoom level. Datashader solves both of these problems.\n",
    "\n",
    "Datashader takes 2 dimensional point data and rapidly turns it into an intesnity map image. Let's try it on the same data as above.\n",
    "\n",
    "We're also going to make use of Geoviews which adds some extra functionality in the Bokeh/Datashader/Holoviews family for working with geographical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "# import datashader.transfer_functions as tf\n",
    "# from datashader.colors import colormap_select, Greys9\n",
    "from datashader.utils import lnglat_to_meters as webm\n",
    "\n",
    "from holoviews.element import tiles\n",
    "from holoviews.operation.datashader import datashade, dynspread\n",
    "from holoviews.streams import RangeXY\n",
    "\n",
    "import geoviews as gv\n",
    "import cartopy.crs as crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to convert our lat long into a map projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_org_locs_df['easting'], gtr_org_locs_df['northing'] = webm(\n",
    "    gtr_org_locs_df['longitude'], gtr_org_locs_df['latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fetch some background map tile images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles = gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colour - An Aside\n",
    "\n",
    "So far, we've been using palettes and colourmaps that come with the plotting libraries. There are also other libraries that provide premade palettes. \n",
    "\n",
    "**Colorcet** is one of these and it focuses on providing *perceptually linear* palettes. Perceptually linear palettes are incrementally changing and account for the percieved difference in intensity of different colours by the human eye to provide a colour scale that is linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=600\n",
    "height=600\n",
    "cmap = colorcet.kbc\n",
    "\n",
    "opts = dict(width=width, height=height, x_sampling=1, y_sampling=1, cmap=cmap, dynamic=False)\n",
    "tile_opts  = dict(width=width, height=height, xaxis=None, yaxis=None, bgcolor='white', show_grid=False)\n",
    "\n",
    "def make_view(x_range, y_range, **kwargs):\n",
    "    tiles = map_tiles.options(alpha=0.5, **tile_opts)\n",
    "    points = hv.Points(gtr_org_locs_singles, ['easting', 'northing'])\n",
    "    d = dynspread(datashade(points, x_range=x_range, y_range=y_range, **opts), shape='circle', threshold=.1)\n",
    "    return d * tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = hv.DynamicMap(make_view, streams=[RangeXY()])\n",
    "# plot = hv.renderer('bokeh').instance(mode='server').get_plot(dmap)\n",
    "dmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDG Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg = sdg_web_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_definitions = {\n",
    "     1: '1. No Poverty',\n",
    "     2: '2. Zero Hunger',\n",
    "     3: '3. Good Health & Well-being',\n",
    "     4: '4. Quality Education',\n",
    "     5: '5. Gender Equality',\n",
    "     6: '6. Clean Water & Sanitation',\n",
    "     7: '7. Affordable & Clean Energy',\n",
    "     8: '8. Decent Work & Economic Growth',\n",
    "     9: '9. Industry, Innovation & Infrastructure',\n",
    "     10: '10.  Reduced Inequalities',\n",
    "     11: '11.  Sustainable Cities & Communities',\n",
    "     12: '12.  Responsible Consumption & Production',\n",
    "     13: '13.  Climate Action',\n",
    "     14: '14.  Life Below Water',\n",
    "     15: '15.  Life on Land',\n",
    "     16: '16.  Peace, Justice & Strong Institutions',\n",
    "     17: '17.  Partnerships for the Goals'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_goal(l, goal=17):\n",
    "    new_goals = [g for g in l if g != goal]\n",
    "    return new_goals\n",
    "\n",
    "df_sdg['sdg_goals'] = df_sdg['sdg_goals'].apply(remove_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg['n_goals'] = [len(x) for x in df_sdg['sdg_goals']]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df_sdg['n_goals'].value_counts().plot.bar(ax=ax)\n",
    "ax.set_title('Number SDGs per Article')\n",
    "ax.set_xlabel('N Goals')\n",
    "ax.set_ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg = df_sdg[(df_sdg['n_goals'] > 0) & (df_sdg['n_goals'] < 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_counts = pd.Series(chain(*df_sdg['sdg_goals'])).map(sdg_definitions).value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sdg_counts.plot.barh(ax=ax)\n",
    "ax.set_title('Frequency of Goals')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Goal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_sdg['text'].str.len(), bins=100)\n",
    "ax.set_title('Text Length')\n",
    "ax.set_xlabel('N Characters')\n",
    "ax.set_ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg = df_sdg[df_sdg['text'].str.len() > 140]\n",
    "df_sdg = df_sdg.drop_duplicates('text')\n",
    "df_sdg = df_sdg.drop('index', axis=1)\n",
    "df_sdg = df_sdg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from im_tutorials.features.text_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [list(chain(*tokenize_document(document))) for document in df_sdg['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phraser, Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(tokenized, min_count=10)\n",
    "phraser = Phraser(phrases)\n",
    "bigrammed = [phraser[d] for d in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(phraser.phrasegrams))\n",
    "phraser.phrasegrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "term_counts = Counter(chain(*bigrammed))\n",
    "term_counts.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['development', 'sdg', 'new', 'global', 'also', 'including', 'support', 'international',\n",
    "             'report', 'implementation', 'national', 'said', 'agenda', 'meeting', 'regional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrammed = [' '.join([t for t in d if t not in stop_words]) for d in bigrammed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrammed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE, Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(bigrammed, min_df=10, max_df=0.5)\n",
    "tfidf_vecs = tfidf.fit_transform(bigrammed)\n",
    "svd = TruncatedSVD(n_components=30)\n",
    "svd_vecs = svd.fit_transform(tfidf_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "tsne_vecs = tsne.fit_transform(svd_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "from bokeh.palettes import Category20_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_goals = (df_sdg[df_sdg['n_goals'] == 1]).index.values\n",
    "tsne_vecs_single = tsne_vecs[single_goals]\n",
    "goal_labels_single = [g[0] for g in df_sdg['sdg_goals'][single_goals]]\n",
    "titles_single = df_sdg['title'][single_goals].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [Category20_16[g-1] for g in goal_labels_single]\n",
    "\n",
    "cds = ColumnDataSource(data={\n",
    "    'tsne_0': tsne_vecs[:, 0][single_goals],\n",
    "    'tsne_1': tsne_vecs[:, 1][single_goals],\n",
    "    'color': colors,\n",
    "    'goal': [sdg_definitions[g] for g in goal_labels_single],\n",
    "    'title': titles_single,\n",
    "    'id': single_goals\n",
    "})\n",
    "\n",
    "p = figure(width=900, title='TSNE Plot of Single SDG Article Vectors')\n",
    "\n",
    "hover = HoverTool(tooltips=[('Goal', '@goal'), ('Title', '@title'), ('ID', '@id')])\n",
    "\n",
    "p.circle(source=cds, x='tsne_0', y='tsne_1', color='color', line_width=0, legend='goal', radius=0.4, alpha=0.9)\n",
    "p.add_tools(hover)\n",
    "\n",
    "show(p)\n",
    "# output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_projects_funds_df['abstractText'].fillna('', inplace=True)\n",
    "gtr_projects_funds_df['techAbstractText'].fillna('', inplace=True)\n",
    "gtr_projects_df['full_text'] = (gtr_projects_funds_df['abstractText'] \n",
    "                                + ' ' \n",
    "                                + gtr_projects_funds_df['techAbstractText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = gtr_projects_df['full_text'].str.len()\n",
    "hist = np.histogram(lens, bins=2000)\n",
    "df_hist = pd.DataFrame(hist).T\n",
    "df_hist[0] = df_hist[0].cumsum() / df_hist[0].cumsum().max() * 100\n",
    "df_hist.columns = ['Freq', 'Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover = HoverTool(\n",
    "    tooltips=[\n",
    "        ('Length', '@{Length}'), \n",
    "        ('Percentile', '@{Freq} %')], \n",
    "    mode='vline')\n",
    "c = hv.Curve(df_hist, 'Length', 'Freq')\n",
    "c.opts(tools=[hover])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_text_df = gtr_projects_df[gtr_projects_df['full_text'].str.len() > 280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_topic_link = gtr_link_table('topic')\n",
    "gtr_topics_df = gtr_table('topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(gtr_topics_df['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_topic_link['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_topics_df.set_index('id').loc['FB535BD0-E265-4C0A-8532-32DCB83A3951']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_id = gtr_topics_df[gtr_topics_df['text'].str.startswith('Tools, tech')].iloc[0]['id']\n",
    "subset_ids = gtr_topic_link[gtr_topic_link['id'] == topic_id]['project_id']\n",
    "topic_projects_df = gtr_projects_df.set_index('id').loc[subset_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_projects_df['leadFunder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_projects_df = gtr_projects_df.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vecs = TfidfVectorizer(min_df=10, max_df=.2).fit_transform(topic_projects_df['full_text'])\n",
    "svd_vecs = TruncatedSVD(n_components=30).fit_transform(text_vecs)\n",
    "tsne_vecs = TSNE().fit_transform(svd_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = topic_projects_df['leadFunder'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Category10_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [Category10_10[g] for g in s]\n",
    "\n",
    "cds = ColumnDataSource(data={\n",
    "    'tsne_0': tsne_vecs[:, 0],\n",
    "    'tsne_1': tsne_vecs[:, 1],\n",
    "    'color': colors,\n",
    "    'funder': topic_projects_df['leadFunder'].values,\n",
    "#     'goal': [sdg_definitions[g] for g in goal_labels_single],\n",
    "    'title': topic_projects_df['title'],\n",
    "#     'id': single_goals\n",
    "})\n",
    "\n",
    "p = figure(width=900, title='TSNE Plot of Single SDG Article Vectors')\n",
    "\n",
    "hover = HoverTool(tooltips=[('Funder', '@funder'), ('Title', '@title')])\n",
    "\n",
    "p.circle(source=cds, x='tsne_0', y='tsne_1', color='color', line_width=0, legend='goal', radius=0.4, alpha=0.9)\n",
    "p.add_tools(hover)\n",
    "\n",
    "show(p)\n",
    "# output_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_projects_funds_df['full_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organisation Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_curve(phase, freq):\n",
    "    xvals = [0.1* i for i in range(100)]\n",
    "    return hv.Curve((xvals, [np.sin(phase+freq*x) for x in xvals]))\n",
    "\n",
    "curve_dict = {f:sine_curve(0,f) for f in frequencies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi_line_plot():\n",
    "    \n",
    "\n",
    "hv.NdOverlay(\n",
    "    {c: hv.Path((amount_year_sum.index.values, amount_year_sum[c])) for c in amount_year_sum.columns}).opts(\n",
    "    'Histogram', width=1000, alpha=0.8, muted_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndoverlay = hv.NdOverlay(curve_dict, kdims='frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.layout import random_layout, circular_layout, forceatlas2_layout\n",
    "from datashader.bundling import connect_edges, hammer_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_layout(graph):\n",
    "    layout = nx.spring_layout(graph)\n",
    "    data = [[node]+layout[node].tolist() for node in graph.nodes]\n",
    "\n",
    "    nodes = pd.DataFrame(data, columns=['id', 'x', 'y'])\n",
    "    nodes.set_index('id', inplace=True)\n",
    "\n",
    "    edges = pd.DataFrame(list(graph.edges), columns=['source', 'target'])\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_n, pos_e = nx_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nx_plot(graph, name=\"\"):\n",
    "    print(graph.name, len(graph.edges))\n",
    "    nodes, edges = nx_layout(graph)\n",
    "    \n",
    "    direct = connect_edges(nodes, edges)\n",
    "    bundled_bw005 = hammer_bundle(nodes, edges)\n",
    "    bundled_bw030 = hammer_bundle(nodes, edges, initial_bandwidth=0.07)\n",
    "\n",
    "    return [graphplot(nodes, direct,         graph.name),\n",
    "            graphplot(nodes, bundled_bw005, \"Bundled bw=0.05\"),\n",
    "            graphplot(nodes, bundled_bw030, \"Bundled bw=0.09\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgesplot(edges, name=None, canvas=None):\n",
    "    canvas = ds.Canvas(**cvsopts) if canvas is None else canvas\n",
    "    return tf.shade(canvas.line(edges, 'x','y', agg=ds.count()), name=name)\n",
    "    \n",
    "def graphplot(nodes, edges, name=\"\", canvas=None, cat=None):\n",
    "    if canvas is None:\n",
    "        xr = nodes.x.min(), nodes.x.max()\n",
    "        yr = nodes.y.min(), nodes.y.max()\n",
    "        canvas = ds.Canvas(x_range=xr, y_range=yr, **cvsopts)\n",
    "        \n",
    "    np = nodesplot(nodes, name + \" nodes\", canvas, cat)\n",
    "    ep = edgesplot(edges, name + \" edges\", canvas)\n",
    "    return tf.stack(ep, np, how=\"over\", name=name)\n",
    "\n",
    "def nodesplot(nodes, name=None, canvas=None, cat=None):\n",
    "    canvas = ds.Canvas(**cvsopts) if canvas is None else canvas\n",
    "    aggregator=None if cat is None else ds.count_cat(cat)\n",
    "    agg=canvas.points(nodes,'x','y',aggregator)\n",
    "    return tf.spread(tf.shade(agg, cmap=[\"#FF3333\"]), px=3, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvsopts = dict(plot_height=400, plot_width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = [nx_plot(g) for g in [G]]\n",
    "\n",
    "tf.Images(*chain.from_iterable(plots)).cols(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(amount_year_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_year_sum = amount_year_sum.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = hv.Curve(amount_year_sum, 'start_y', 'EPSRC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(NLINES)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.NdOverlay(\n",
    "    {c: hv.Path((amount_year_sum.index.values, amount_year_sum[c])) for c in amount_year_sum.columns}).opts(\n",
    "    'Histogram', width=1000, alpha=0.8, muted_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Path(aamount_year_sum.columns, amount_year_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.arange(N), np.random.rand(N, NLINES) + np.arange(NLINES)[np.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.help(hv.Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(np.log10(gtr_funds_df[gtr_funds_df['amount'] > 0]\n",
    "                 .groupby('project_id')['amount'].sum()), bins=100);\n",
    "# ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datashader Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtr = df_gtr[(df_gtr['rel'] == 'LEAD_ORG') |\n",
    "               (df_gtr['rel'] == 'COLLAB_ORG') | \n",
    "               (df_gtr['rel'] == 'PARTICIPANT_ORG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df_gtr['id'].value_counts() > 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gtr['rel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtr_df = gtr_df[~pd.isnull(gtr_df['research_topics'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = sorted(set(chain(*gtr_df['research_topics'])))\n",
    "mlb = MultiLabelBinarizer(classes=topics)\n",
    "df_topics = pd.DataFrame(mlb.fit_transform(gtr_df['research_topics']), columns=topics)\n",
    "df_topics = df_topics.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=30)\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "svd_vecs = svd.fit_transform(df_topics)\n",
    "tsne_vecs = tsne.fit_transform(svd_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.sklearn_api.phrases import PhrasesTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AnnoyIndex(30, 'angular')  # Length of item vector that will be indexed\n",
    "for i in range(df_topics.shape[0]):\n",
    "    t.add_item(i, svd_vecs[i])\n",
    "    \n",
    "t.build(500) # 10 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist = 0.9\n",
    "\n",
    "dists = {}\n",
    "edges = []\n",
    "for i in range(df_topics.shape[0]):\n",
    "    closest = t.get_nns_by_item(i, 5)\n",
    "    source = df_topics.index[closest[0]]\n",
    "    closest = t.get_nns_by_item(i, 5)[1:]\n",
    "    for n in closest:\n",
    "        dist = t.get_distance(i, n)\n",
    "        if dist <= min_dist:\n",
    "            ns = df_topics.index[n]\n",
    "            edge = tuple(sorted([source, ns]))\n",
    "            edges.append(edge)\n",
    "            dists[edge] = dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = []\n",
    "for k, v in Counter(edges).items():\n",
    "    edge_list.append([k[0], k[1], {'weight': dists[k]}])\n",
    "    \n",
    "g = nx.Graph()\n",
    "g.add_edges_from(edge_list)\n",
    "\n",
    "nx.draw(g, node_size=25, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne_vecs[:, 0], tsne_vecs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders_time_df = gtr_df.groupby(['start_year', 'funder_name'])['project_id'].count().unstack().loc[2006:2016]\n",
    "cds = ColumnDataSource.from_df(funders_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders_time_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.palettes import Category20_11\n",
    "from bokeh.models import HoverTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = Category20_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cmap.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover = HoverTool(tooltips=[], mode='vline')\n",
    "\n",
    "p = figure()\n",
    "\n",
    "for i, c in enumerate(funders_time_df.columns):\n",
    "    p.line(source=cds, x='start_year', y=c, line_width=2, alpha=0.9, color=Category20_11[i],\n",
    "          name='x')\n",
    "    hover.tooltips.append((f'{c}', f'@{c}'))\n",
    "p.add_tools(hover)\n",
    "    \n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
